{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = '/home/nogaschw/Codeworkout/cleaned_code.csv'\n",
    "df = pd.read_csv(csv_file_path, sep=',')\n",
    "df = df[df.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_file_path = '/home/nogaschw/Codeworkout/cleaned_questions.csv'\n",
    "\n",
    "questions = pd.read_csv(cleaned_file_path, sep=',')\n",
    "questions = questions[questions.columns[1:]]\n",
    "questions = questions[questions['max_score'] != 0]\n",
    "questions['prompt'] = questions['prompt'].apply(lambda x: x.split('PROBLEM STATEMENT:')[-1] if x.__contains__(\"PROBLEM STATEMENT:\") else x) # clean question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['problem_id'] = df['problem_id'].apply(lambda x: x.lower())\n",
    "questions['id'] = questions['id'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3661160/3206372099.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(['student_id', 'problem_id', 'course_id']).apply(lambda x: pd.Series({\n"
     ]
    }
   ],
   "source": [
    "df['timestamp'] = pd.to_datetime(df['timestamp'], format='%Y-%m-%d %H:%M:%S')\n",
    "df = df.sort_values('timestamp', ascending=True)\n",
    "df = df.groupby(['student_id', 'problem_id', 'course_id']).apply(lambda x: pd.Series({\n",
    "    'ServerTimestamp': x['timestamp'].tolist(),\n",
    "    'score': x['score'].tolist(),\n",
    "    'source_code': x['clean_code'].tolist()\n",
    "})).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_after_max(score, snapshots, ServerTimestamp):\n",
    "    max_index = len(score) - 1 - score[::-1].index(max(score))\n",
    "    return score[:max_index+1], snapshots[:max_index+1], ServerTimestamp[:max_index+1]\n",
    "\n",
    "# Apply the function to each row\n",
    "df['score'], df['source_code'], df['ServerTimestamp'] = zip(*df.apply(lambda row: trim_after_max(row['score'], row['source_code'], row['ServerTimestamp']), axis=1))\n",
    "df['start_time'] = [i[0] for i in df['ServerTimestamp']]\n",
    "df['end_time'] = [i[-1] for i in df['ServerTimestamp']]\n",
    "df['max_score'] = [max(i) for i in df['score']]\n",
    "df['num_snapshots'] = df['source_code'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles = df.groupby('problem_id')['num_snapshots'].apply(lambda x: np.percentile(x, 75)).reset_index()\n",
    "percentiles.columns = ['problem_id', '75th_percentile']\n",
    "df = df.merge(percentiles, on='problem_id')\n",
    "df['below_75th_percentile'] = df.apply(lambda row: row['num_snapshots'] <= row['75th_percentile'], axis=1)\n",
    "df['correct_eventually'] = df.apply(lambda row: row['max_score'] >= 100, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Label'] = df.apply(lambda row: row['correct_eventually'] & row['below_75th_percentile'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "True     90387\n",
       "False    64677\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12353\n"
     ]
    }
   ],
   "source": [
    "print(len(df[df['max_score'] == -1]))\n",
    "df = df[df['max_score'] != -1] # remove all the rows contain only locall code (not really the grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_basic = df.merge(questions, how='inner', left_on=['problem_id', 'course_id'], right_on=['id', 'course_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_basic = df_basic[df_basic['type'] != 'project']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "True     81818\n",
       "False    46860\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_basic['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_basic = df_basic[['student_id', 'problem_id', 'course_id', 'type', 'start_time', 'end_time', 'score', 'source_code', 'prompt', 'correct_eventually','below_75th_percentile', 'num_snapshots', 'Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df_basic.sort_values(by=['student_id', 'end_time'])\n",
    "df_sorted['row_number'] = df_sorted.groupby(['student_id', 'course_id']).cumcount() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_code = df_sorted['source_code'].tolist()\n",
    "prev_code.insert(0, [])\n",
    "prev_q = df_sorted['prompt'].tolist()\n",
    "prev_q.insert(0, [])\n",
    "prev_num_q = df_sorted['problem_id'].tolist()\n",
    "prev_num_q.insert(0, [])\n",
    "prev_score = df_sorted['score'].tolist()\n",
    "prev_score.insert(0, [])\n",
    "prev_label = df_sorted['Label'].tolist()\n",
    "prev_label.insert(False, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted['prev_code'] = prev_code[:-1] # last question of the last student\n",
    "df_sorted['prev_question'] = prev_q[:-1]\n",
    "df_sorted['prev_question_num'] = prev_num_q[:-1]\n",
    "df_sorted['prev_score'] = prev_score[:-1]\n",
    "df_sorted['prev_label'] = prev_label[:-1]\n",
    "\n",
    "df_sorted = df_sorted[df_sorted['row_number'] != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_code = []\n",
    "prev_question = []\n",
    "prev_q_num = []\n",
    "prev_score = []\n",
    "prev_label = []\n",
    "for i, row in df_sorted.iterrows():\n",
    "    if row['row_number'] == 2:\n",
    "        prev_code.append([row['prev_code']])\n",
    "        prev_question.append([row['prev_question']])\n",
    "        prev_q_num.append([row['prev_question_num']])\n",
    "        prev_score.append([row['prev_score']])\n",
    "        prev_label.append([row['prev_label']])\n",
    "    else:\n",
    "        prev_code.append(prev_code[-1] + [row['prev_code']])\n",
    "        prev_question.append(prev_question[-1] + [row['prev_question']])\n",
    "        prev_q_num.append(prev_q_num[-1] + [row['prev_question_num']])\n",
    "        prev_score.append(prev_score[-1] + [row['prev_score']])\n",
    "        prev_label.append(prev_label[-1] + [row['prev_label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted['prev_code'] = prev_code\n",
    "df_sorted['prev_question'] = prev_question\n",
    "df_sorted['prev_question_num'] = prev_q_num\n",
    "df_sorted['score'] = prev_score\n",
    "df_sorted['prev_label'] = prev_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_with_compu = questions.copy()\n",
    "q_with_compu['IfElse'] = questions['conditional']\n",
    "q_with_compu['Loops'] = questions[[\"loop_counting\", \"loop_until\", \"loop_elements\", \"loop_nested\"]].max(axis=1)\n",
    "q_with_compu['MathOperations'] = questions[[\"stat_calculate\", \"assignment\"]].max(axis=1)\n",
    "q_with_compu['LogicOperators'] = 0\n",
    "q_with_compu['StringOperations'] = questions[[\"input_str\", \"input_cast\", \"output\"]].max(axis=1)\n",
    "q_with_compu[\"List\"]= questions[[\"list\", \"list_2d\"]].max(axis=1)\n",
    "q_with_compu['FileOperations'] = questions[[\"file_read\", \"file_write\"]].max(axis=1)\n",
    "q_with_compu[\"Functions\"] = questions[[\"function_call\", \"function_def\", \"function_return\"]].max(axis=1)\n",
    "q_with_compu['Dictionary'] = questions[\"dictionary\"]\n",
    "q_with_compu['Tuple'] = questions[[\"tuple\", \"item_set\"]].max(axis=1)\n",
    "\n",
    "q_with_compu = q_with_compu.drop(columns=['input_str', 'input_cast', 'output', 'assignment', 'conditional',\n",
    "       'function_call', 'function_def', 'function_return', 'loop_counting',\n",
    "       'loop_until', 'loop_elements', 'loop_nested', 'stat_calculate',\n",
    "       'file_read', 'file_write', 'list', 'list_2d', 'dictionary', 'item_set',\n",
    "       'tuple'])\n",
    "\n",
    "\n",
    "q_with_compu.fillna(0, inplace=True)\n",
    "questions.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_with_compu = q_with_compu.rename(columns={'prompt': 'question'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxonomy = df_sorted.merge(q_with_compu.drop(columns=['type']), how='left', left_on=['problem_id', 'course_id'], right_on=['id', 'course_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxonomy = df_taxonomy[['student_id', 'course_id', 'problem_id', 'prev_code', 'prev_question', 'prev_question_num', 'score', 'question', 'prev_label', 'correct_eventually' ,'below_75th_percentile', 'num_snapshots', 'Label', 'type', 'IfElse', 'Loops',\n",
    "       'MathOperations', 'LogicOperators', 'StringOperations', 'List', 'FileOperations', 'Functions', 'Dictionary', 'Tuple']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'/home/nogaschw/Codeworkout/Thesis/Data/falcon/split_ids_valid_ids.pkl', 'rb') as f:\n",
    "#         valid_ids = pickle.load(f)\n",
    "# with open(f'/home/nogaschw/Codeworkout/Thesis/Data/falcon/split_ids_test_ids.pkl', 'rb') as f:\n",
    "#     test_ids = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_df = df_taxonomy[df_taxonomy['student_id'].isin(valid_ids)]\n",
    "# test_df = df_taxonomy[df_taxonomy['student_id'].isin(test_ids)]\n",
    "# pd.concat([valid_df, test_df], ignore_index=True).to_pickle(os.path.join(cwd, '../df_taxonomy_falcon_test_valid.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_snapshots_num():\n",
    "    arr_snapshot_num = []\n",
    "    max_snapshots = 0\n",
    "    max_total = 0\n",
    "    max_row_snapshots = None\n",
    "    max_row_total = None\n",
    "    for j, row in df_taxonomy.iterrows():\n",
    "        r = row['prev_code']\n",
    "        sum_snapshots = 0\n",
    "        for i in r:\n",
    "            sum_snapshots += len(i)\n",
    "            arr_snapshot_num.append(len(i))\n",
    "            if len(i) > max_snapshots:\n",
    "                max_snapshots = len(i)\n",
    "                max_row_snapshots = row\n",
    "        if sum_snapshots > max_total:\n",
    "            max_total = sum_snapshots\n",
    "            max_row_total = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxonomy.to_pickle(os.path.join(cwd, '../df_taxonomy_falcon_new_label.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
