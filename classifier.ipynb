{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nogaschw/.conda/envs/env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wandb\n",
    "import torch\n",
    "from Data import *\n",
    "import pandas as pd\n",
    "from helper import *\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import get_scheduler\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f5e26863510>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nogaschw/.conda/envs/env/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "from Data_Embedding import *\n",
    "# from BasicsModels import *\n",
    "# from TaxonomyModel import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnogaschw\u001b[0m (\u001b[33mnaji1\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_df(path):\n",
    "#     df = pd.read_csv(path, sep=',')\n",
    "#     print(f\"finish the read {len(df)}\")\n",
    "#     df['prev_code'] = df['prev_code'].apply(ast.literal_eval)\n",
    "#     df['prev_question'] = df['prev_question'].apply(ast.literal_eval)\n",
    "#     df['score'] = df['score'].apply(ast.literal_eval)\n",
    "#     print(f'Create df...')\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/sise/home/nogaschw/Codeworkout/Thesis/wandb/run-20240911_144339-tzdc2pbo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/naji1/Struggling%20Students/runs/tzdc2pbo' target=\"_blank\">Full without history</a></strong> to <a href='https://wandb.ai/naji1/Struggling%20Students' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/naji1/Struggling%20Students' target=\"_blank\">https://wandb.ai/naji1/Struggling%20Students</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/naji1/Struggling%20Students/runs/tzdc2pbo' target=\"_blank\">https://wandb.ai/naji1/Struggling%20Students/runs/tzdc2pbo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    project=\"Struggling Students\",\n",
    "    name=\"Full without history\",\n",
    "    tags=[\"baseline\", \"falconcode_course4\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "struggling\n",
       "0    30387\n",
       "1     6455\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/home/nogaschw/Codeworkout/df_taxonomy_falcon4.pkl\"\n",
    "df_falcon = pd.read_pickle(path)\n",
    "\n",
    "df_falcon['struggling'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/nogaschw/Codeworkout/py&javaTax.csv\"\n",
    "df_codeworkout = get_df(path)\n",
    "df_codeworkout['struggling'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"/home/nogaschw/Codeworkout/df_taxonomy_all.csv\"\n",
    "# df_tax = get_df(path)\n",
    "# df_tax['struggling'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model_name = 'distilbert/distilbert-base-uncased'\n",
    "code_model_name = 'microsoft/codebert-base'\n",
    "\n",
    "text_tokenizer = AutoTokenizer.from_pretrained(text_model_name)\n",
    "code_tokenizer = AutoTokenizer.from_pretrained(code_model_name)\n",
    "if text_tokenizer.pad_token is None:\n",
    "    text_tokenizer.pad_token = text_tokenizer.eos_token\n",
    "if code_tokenizer.pad_token is None:\n",
    "    code_tokenizer.pad_token = code_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(columns=['model_name', 'threshold', 'roc_auc', 'accuracy', 'precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "lr = 0.00001\n",
    "all_questions = 0\n",
    "taxonomy = 1\n",
    "balance_def = 0\n",
    "mean = 0\n",
    "\n",
    "balance_def = [same_df, oversampling_boosting, oversampling_df, undersampling_df, oversampling_augmentation][balance_def]\n",
    "\n",
    "name = f'{[\"\", \"Mean_\"][mean]}{\"All_History_with\"}_{[\"Current_Question\", \"All_Question\", \"FullyConnected\"][all_questions]}_{hidden_size}_{num_layers}_{lr}_{balance_def.__name__}'\n",
    "\n",
    "dataset = [DatasetCodeQuestion, DatasetCodeQPrevQ, DatasetLimitMean][all_questions]\n",
    "\n",
    "# model = [CodeQuestionLSTMModel(text_model_name, code_model_name, hidden_size, num_layers),\n",
    "#             CodeQPrevQLSTMModel(text_model_name, code_model_name, hidden_size, num_layers, mean=mean),\n",
    "#             FullyConnectedNetwork(code_model_name, 10, 2, 1)][all_questions]\n",
    "feature = None\n",
    "\n",
    "# if taxonomy:\n",
    "#     dataset = FeatureDataset\n",
    "#     # feature =['If/Else', 'NestedIf', 'While', 'For', 'NestedFor', 'Math+-*/', 'Math%', 'LogicAndNotOr', 'LogicCompareNum', 'LogicBoolean', 'StringFormat', 'StringConcat', 'StringIndex', 'StringLen', 'StringEqual', 'CharEqual', 'ArrayIndex', 'DefFunction']\n",
    "#     # feature = ['LogicBoolean','StringLen', 'StringEqual', 'CharEqual', 'ArrayIndex', 'DefFunction', 'IfKnowledge', 'StringKnowledge', 'LoopsKnowledge', 'Math+-*/%', 'LogicOperators']\n",
    "feature = ['IfElse', 'Loops', 'MathOperations', 'LogicOperators', 'StringOperations', 'List', 'FileOperations', 'Functions', 'Dictionary', 'Tuple']\n",
    "    # model = ModelComputationalConstructs(model, hidden_size, len(feature))\n",
    "name = f'Taxonomy_{[\"Current_Question\", \"All_Question\"][all_questions]}_{hidden_size}_{num_layers}_{lr}_{balance_def.__name__}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_falcon[df_falcon['type'] != 'lab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load exist spliting\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, valid_dataloader, test_dataloader = create_data_loader(df, DatasetCodeQuestion, text_tokenizer, code_tokenizer, batch_size=64, balanced_def=balance_def, feature=feature, ids_filepath_prefix=\"/home/nogaschw/Codeworkout/Thesis/Data/falcon/split_ids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124, 17, 36)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader), len(valid_dataloader), len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  save_ids(set(train_dataloader.dataset.df['student_id']), (set(valid_dataloader.dataset.df['student_id'])), (set(test_dataloader.dataset.df['student_id'])), \"Data/falcon/split_ids\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NoAll_History_with_Current_Question_128_2_1e-05_same_df.pth',\n",
       " 'All_History_with_Current_Question_128_2_1e-05_same_df.pth',\n",
       " 'All_History_with_Current_Question_128_2_1e-05_oversampling_df.pth',\n",
       " 'lossAll_History_with_Current_Question_128_2_1e-05_oversampling_df.pth',\n",
       " 'lossAll_History_with_Current_Question_128_2_1e-05_oversampling_augmentation.pth',\n",
       " 'Mean_All_History_with_All_Question_128_2_1e-05_oversampling_df.pth',\n",
       " 'All_History_with_Current_Question_264_2_1e-05_same_df.pth',\n",
       " 'All_History_with_Current_Question_128_1_1e-05_same_df.pth',\n",
       " 'Taxonomy_Current_Question_128_2_1e-05_same_df.pth',\n",
       " 'All_History_with_All_Question_128_2_1e-05_same_df.pth',\n",
       " 'Taxonomy_All_Question_128_2_1e-05_same_df.pth',\n",
       " 'All_History_with_FullyConnected_128_2_1e-05_oversampling_augmentation.pth',\n",
       " 'All_History_with_FullyConnected10_128_2_1e-05_oversampling_augmentation.pth']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_models = \"/home/nogaschw/Codeworkout/Thesis/Models\"\n",
    "files = os.listdir(path_models)\n",
    "display(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TaxonomyModel import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "model = CodeQuestionLSTMModel_Embedding(text_model_name, hidden_size, num_layers)\n",
    "model = ModelComputationalConstructs_Embedding(model, hidden_size, len(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nogaschw/Codeworkout/Thesis/Models/Taxonomy_Current_Question_128_2_1e-05_same_df.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_972143/3871524362.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path_name))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModelComputationalConstructs_Embedding(\n",
       "  (base_model): CodeQuestionLSTMModel_Embedding(\n",
       "    (text_model): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSdpaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (lstm): LSTM(768, 128, num_layers=2, batch_first=True)\n",
       "    (fc): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       "  (final_linear): Linear(in_features=138, out_features=1, bias=True)\n",
       "  (normalizer): BatchNorm1d(138, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path_name = os.path.join(path_models, f\"{name}.pth\")\n",
    "print(model_path_name)\n",
    "model.load_state_dict(torch.load(model_path_name))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated memory: 1786.20 MB\n",
      "Cached memory: 4804.00 MB\n",
      "Max memory allocated: 3036.42 MB\n",
      "Max memory reserved: 4804.00 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Allocated memory: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "print(f\"Cached memory: {torch.cuda.memory_reserved() / 1024**2:.2f} MB\")\n",
    "print(f\"Max memory allocated: {torch.cuda.max_memory_allocated() / 1024**2:.2f} MB\")\n",
    "print(f\"Max memory reserved: {torch.cuda.max_memory_reserved() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Taxonomy_Current_Question_128_2_1e-05_same_df'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 from 190\n"
     ]
    }
   ],
   "source": [
    "all_labels, all_probs = eval_loop(model, valid_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(all_labels, all_probs)\n",
    "\n",
    "# Calculate the AUC (Area Under the Curve)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Diagonal line (random classifier)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best threshold is: 0.4795159697532654\n"
     ]
    }
   ],
   "source": [
    "J = tpr - fpr\n",
    "best_index = J.argmax()\n",
    "best_threshold = thresholds[best_index]\n",
    "print(f\"The best threshold is: {best_threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 from 393\n"
     ]
    }
   ],
   "source": [
    "y_labels, y_probs = eval_loop(model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sise/home/nogaschw/Codeworkout/Thesis/helper.py:105: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([pd.DataFrame([[model_name, threshold, roc_auc, accuracy, precision, recall, f1]], columns=df.columns), df], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>threshold</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Taxonomy_Current_Question_128_2_1e-05_same_df</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.763816</td>\n",
       "      <td>0.780567</td>\n",
       "      <td>0.438664</td>\n",
       "      <td>0.575037</td>\n",
       "      <td>0.497677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      model_name  threshold   roc_auc  \\\n",
       "0  Taxonomy_Current_Question_128_2_1e-05_same_df        0.6  0.763816   \n",
       "\n",
       "   accuracy  precision    recall        f1  \n",
       "0  0.780567   0.438664  0.575037  0.497677  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results(df_results, name, 0.6, y_labels, y_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14919,  5463],\n",
       "       [ 1542,  3209]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_labels, np.round(y_probs))\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "set()\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "# Check data leak\n",
    "print(set(train_dataloader.dataset.df['student_id']).intersection(set(test_dataloader.dataset.df['student_id'])))\n",
    "print(set(valid_dataloader.dataset.df['student_id']).intersection(set(test_dataloader.dataset.df['student_id'])))\n",
    "print(set(valid_dataloader.dataset.df['student_id']).intersection(set(train_dataloader.dataset.df['student_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'BasicsModels' from '/sise/home/nogaschw/Codeworkout/Thesis/BasicsModels.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import BasicsModels\n",
    "\n",
    "# Reload the module\n",
    "importlib.reload(BasicsModels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BasicsModels import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QuestionLSTMModel(text_model_name, hidden_size, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weight = torch.tensor([4.0]).to(device) # Adjust this based on your class imbalance\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/09/2024_14:44:51\n",
      "124 17\n",
      "Epoch: 0\n",
      "Batch 0 from 124\n",
      "Batch 100 from 124\n",
      "Test Batch 0 from 17\n",
      "Epoch [1], LR: 0.000010, Loss: 1.2303, Val Loss: 1.2004, patience: 5\n",
      "success deep copy\n",
      "success save in /home/nogaschw/Codeworkout/Thesis/Models/Taxonomy_Current_Question_128_2_1e-05_same_df.pth\n",
      "Epoch: 1\n",
      "Batch 0 from 124\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/sise/home/nogaschw/Codeworkout/Thesis/helper.py:45\u001b[0m, in \u001b[0;36mtraining_loop\u001b[0;34m(model, train_dataloader, test_dataloader, optimizer, criterion, device, name)\u001b[0m\n\u001b[1;32m     42\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     43\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 45\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/sise/home/nogaschw/Codeworkout/Thesis/Data.py:143\u001b[0m, in \u001b[0;36mDatasetCodeQuestion.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    140\u001b[0m text_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_tokenizer(question, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_len_text, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m'\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Tokenize code samples\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m input_ids_stack, attention_mask_stack, code_num \u001b[38;5;241m=\u001b[39m \u001b[43mtokenize_vec\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode_tokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_len_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlimit_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_size_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_input_ids\u001b[39m\u001b[38;5;124m'\u001b[39m: text_inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_attention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m: text_inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m: label\n\u001b[1;32m    152\u001b[0m }\n",
      "File \u001b[0;32m/sise/home/nogaschw/Codeworkout/Thesis/Data.py:103\u001b[0m, in \u001b[0;36mtokenize_vec\u001b[0;34m(tokenizer, samples, max_len, limit_len, padding_size)\u001b[0m\n\u001b[1;32m    100\u001b[0m         flat_code_sampels\u001b[38;5;241m.\u001b[39mextend(i)\n\u001b[1;32m    101\u001b[0m     samples \u001b[38;5;241m=\u001b[39m flat_code_sampels\n\u001b[0;32m--> 103\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_length\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    104\u001b[0m input_ids_stack \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m inputs])\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    105\u001b[0m attention_mask_stack \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m inputs])\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/sise/home/nogaschw/Codeworkout/Thesis/Data.py:103\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    100\u001b[0m         flat_code_sampels\u001b[38;5;241m.\u001b[39mextend(i)\n\u001b[1;32m    101\u001b[0m     samples \u001b[38;5;241m=\u001b[39m flat_code_sampels\n\u001b[0;32m--> 103\u001b[0m inputs \u001b[38;5;241m=\u001b[39m [\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_length\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m samples]\n\u001b[1;32m    104\u001b[0m input_ids_stack \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m inputs])\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    105\u001b[0m attention_mask_stack \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m inputs])\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3073\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3071\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   3072\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 3073\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3075\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3181\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_encode_plus(\n\u001b[1;32m   3161\u001b[0m         batch_text_or_text_pairs\u001b[38;5;241m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[1;32m   3162\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3178\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3179\u001b[0m     )\n\u001b[1;32m   3180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3184\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3199\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3200\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3201\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3255\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3245\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   3246\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   3247\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   3248\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3252\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3253\u001b[0m )\n\u001b[0;32m-> 3255\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3258\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3273\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msplit_special_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3274\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.11/site-packages/transformers/models/roberta/tokenization_roberta_fast.py:235\u001b[0m, in \u001b[0;36mRobertaTokenizerFast._encode_plus\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m is_split_into_words \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_split_into_words\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_prefix_space \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_split_into_words, (\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to instantiate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with add_prefix_space=True \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto use it with pretokenized inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m )\n\u001b[0;32m--> 235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_plus\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.11/site-packages/transformers/tokenization_utils_fast.py:601\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_encode_plus\u001b[39m(\n\u001b[1;32m    579\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    580\u001b[0m     text: Union[TextInput, PreTokenizedInput],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    599\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BatchEncoding:\n\u001b[1;32m    600\u001b[0m     batched_input \u001b[38;5;241m=\u001b[39m [(text, text_pair)] \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;28;01melse\u001b[39;00m [text]\n\u001b[0;32m--> 601\u001b[0m     batched_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatched_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;66;03m# Return tensor is None, then we can remove the leading batch axis\u001b[39;00m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;66;03m# Overflowing tokens are returned as a batch of output so we keep them in this case\u001b[39;00m\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_tensors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_overflowing_tokens:\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.11/site-packages/transformers/models/roberta/tokenization_roberta_fast.py:225\u001b[0m, in \u001b[0;36mRobertaTokenizerFast._batch_encode_plus\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m is_split_into_words \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_split_into_words\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_prefix_space \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_split_into_words, (\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to instantiate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with add_prefix_space=True \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto use it with pretokenized inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    223\u001b[0m )\n\u001b[0;32m--> 225\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.11/site-packages/transformers/tokenization_utils_fast.py:576\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_ids \u001b[38;5;129;01min\u001b[39;00m sanitized_tokens[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eventual_warn_about_too_long_sequence(input_ids, max_length, verbose)\n\u001b[0;32m--> 576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatchEncoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43msanitized_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msanitized_encodings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:227\u001b[0m, in \u001b[0;36mBatchEncoding.__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    223\u001b[0m     n_sequences \u001b[38;5;241m=\u001b[39m encoding[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_sequences\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_sequences \u001b[38;5;241m=\u001b[39m n_sequences\n\u001b[0;32m--> 227\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:762\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    759\u001b[0m     value \u001b[38;5;241m=\u001b[39m [value]\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor(value):\n\u001b[0;32m--> 762\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;66;03m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[39;00m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;66;03m# # at-least2d\u001b[39;00m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;66;03m# if tensor.ndim > 2:\u001b[39;00m\n\u001b[1;32m    767\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor.squeeze(0)\u001b[39;00m\n\u001b[1;32m    768\u001b[0m     \u001b[38;5;66;03m# elif tensor.ndim < 2:\u001b[39;00m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor[None, :]\u001b[39;00m\n\u001b[1;32m    771\u001b[0m     \u001b[38;5;28mself\u001b[39m[key] \u001b[38;5;241m=\u001b[39m tensor\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:724\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors.<locals>.as_tensor\u001b[0;34m(value, dtype)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value[\u001b[38;5;241m0\u001b[39m], np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    723\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39marray(value))\n\u001b[0;32m--> 724\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = training_loop(model=model, train_dataloader=train_dataloader, test_dataloader=valid_dataloader, optimizer=optimizer, criterion=criterion, device=device, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/09/2024_13:33:13\n",
      "407 54\n",
      "Epoch: 0\n",
      "Batch 0 from 407\n",
      "Batch 100 from 407\n",
      "Batch 200 from 407\n",
      "Batch 300 from 407\n",
      "Batch 400 from 407\n",
      "Test Batch 0 from 54\n",
      "Epoch [1], LR: 0.000010, Loss: 1.0589, Val Loss: 1.0524, patience: 5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You must pass an instance of wandb.Artifact or a valid file path to log_artifact",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/sise/home/nogaschw/Codeworkout/Thesis/helper.py:81\u001b[0m, in \u001b[0;36mtraining_loop\u001b[0;34m(model, train_dataloader, test_dataloader, optimizer, criterion, device, name)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m avg_loss_valid \u001b[38;5;241m<\u001b[39m best_loss:\n\u001b[1;32m     80\u001b[0m     best_loss \u001b[38;5;241m=\u001b[39m avg_loss_valid            \n\u001b[0;32m---> 81\u001b[0m     \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     best_model_weights \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(model\u001b[38;5;241m.\u001b[39mstate_dict())  \u001b[38;5;66;03m# Deep copy here      \u001b[39;00m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuccess deep copy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:403\u001b[0m, in \u001b[0;36m_run_decorator._noop_on_finish.<locals>.decorator_fn.<locals>.wrapper_fn\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper_fn\u001b[39m(\u001b[38;5;28mself\u001b[39m: Type[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_finished\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m     default_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) is finished. The call to `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be ignored. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    407\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease make sure that you are using an active run.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    408\u001b[0m     )\n\u001b[1;32m    409\u001b[0m     resolved_message \u001b[38;5;241m=\u001b[39m message \u001b[38;5;129;01mor\u001b[39;00m default_message\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:393\u001b[0m, in \u001b[0;36m_run_decorator._attach.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_is_attaching \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:3138\u001b[0m, in \u001b[0;36mRun.log_artifact\u001b[0;34m(self, artifact_or_path, name, type, aliases)\u001b[0m\n\u001b[1;32m   3106\u001b[0m \u001b[38;5;129m@_run_decorator\u001b[39m\u001b[38;5;241m.\u001b[39m_noop_on_finish()\n\u001b[1;32m   3107\u001b[0m \u001b[38;5;129m@_run_decorator\u001b[39m\u001b[38;5;241m.\u001b[39m_attach\n\u001b[1;32m   3108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_artifact\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3113\u001b[0m     aliases: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3114\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Artifact:\n\u001b[1;32m   3115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Declare an artifact as an output of a run.\u001b[39;00m\n\u001b[1;32m   3116\u001b[0m \n\u001b[1;32m   3117\u001b[0m \u001b[38;5;124;03m    Arguments:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3136\u001b[0m \u001b[38;5;124;03m        An `Artifact` object.\u001b[39;00m\n\u001b[1;32m   3137\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_artifact\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3139\u001b[0m \u001b[43m        \u001b[49m\u001b[43martifact_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maliases\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maliases\u001b[49m\n\u001b[1;32m   3140\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:3273\u001b[0m, in \u001b[0;36mRun._log_artifact\u001b[0;34m(self, artifact_or_path, name, type, aliases, distributed_id, finalize, is_user_created, use_after_commit)\u001b[0m\n\u001b[1;32m   3269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(invalid \u001b[38;5;129;01min\u001b[39;00m alias \u001b[38;5;28;01mfor\u001b[39;00m alias \u001b[38;5;129;01min\u001b[39;00m aliases \u001b[38;5;28;01mfor\u001b[39;00m invalid \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m   3270\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3271\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAliases must not contain any of the following characters: /, :\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3272\u001b[0m         )\n\u001b[0;32m-> 3273\u001b[0m artifact, aliases \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_artifact\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3274\u001b[0m \u001b[43m    \u001b[49m\u001b[43martifact_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maliases\u001b[49m\n\u001b[1;32m   3275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3276\u001b[0m artifact\u001b[38;5;241m.\u001b[39mdistributed_id \u001b[38;5;241m=\u001b[39m distributed_id\n\u001b[1;32m   3277\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assert_can_log_artifact(artifact)\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:3373\u001b[0m, in \u001b[0;36mRun._prepare_artifact\u001b[0;34m(self, artifact_or_path, name, type, aliases)\u001b[0m\n\u001b[1;32m   3371\u001b[0m     artifact \u001b[38;5;241m=\u001b[39m artifact_or_path\n\u001b[1;32m   3372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(artifact, wandb\u001b[38;5;241m.\u001b[39mArtifact):\n\u001b[0;32m-> 3373\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3374\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must pass an instance of wandb.Artifact or a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3375\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid file path to log_artifact\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3376\u001b[0m     )\n\u001b[1;32m   3377\u001b[0m artifact\u001b[38;5;241m.\u001b[39mfinalize()\n\u001b[1;32m   3378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m artifact, _resolve_aliases(aliases)\n",
      "\u001b[0;31mValueError\u001b[0m: You must pass an instance of wandb.Artifact or a valid file path to log_artifact"
     ]
    }
   ],
   "source": [
    "model = training_loop(model=model, train_dataloader=train_dataloader, test_dataloader=valid_dataloader, optimizer=optimizer, criterion=criterion, device=device, name=name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
